{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorboard\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from auxiliary.laserscan import LaserScan\n",
    "from auxiliary.laserscan import SemLaserScan\n",
    "\n",
    "import random\n",
    "\n",
    "import yaml\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/mnt/raid/xyiheng/kittiDataset/sequences\"\n",
    "TESTLABEL_PATH = \"/mnt/raid/xyiheng/method_predictions/sequences\"\n",
    "NUM_OF_CLASSES = 20\n",
    "BATCH_SIZE = 3\n",
    "SAMPLE_SIZE = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define PointNet new version\n",
    "class PointNet_new(nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension, feature_dimension, isSegmentation):\n",
    "        super(PointNet2, self).__init__()\n",
    "        \n",
    "        self.input_dimension = input_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        self.feature_dimension = feature_dimension\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_dimension, 64, 1)\n",
    "        #self.batch1 = nn.BatchNorm1d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        #self.batch2 = nn.BatchNorm1d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 128, 1)\n",
    "        #self.batch3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(128, 512, 1)\n",
    "        #self.batch4 = nn.BatchNorm1d(512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(512, self.feature_dimension, 1)\n",
    "        #self.batch5 = nn.BatchNorm1d(self.feature_dimension)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.conv6 = nn.Conv1d(835 + self.feature_dimension, 256, 1)\n",
    "        #self.batch6 = nn.BatchNorm1d(256)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv7 = nn.Conv1d(256, 256, 1)\n",
    "        #self.batch7 = nn.BatchNorm1d(256)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv8 = nn.Conv1d(256, 128, 1)\n",
    "        #self.batch8 = nn.BatchNorm1d(128)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv9 = nn.Conv1d(128, self.output_dimension, 1)\n",
    "        \n",
    "        self.isSegmentation = isSegmentation\n",
    "\n",
    "    def forward(self, cp):\n",
    "        B, N = cp.shape[0], cp.shape[1]\n",
    "        cp = cp.permute(0, 2, 1)\n",
    "        cp_copy_0 = cp\n",
    "\n",
    "        cp = self.conv1(cp)\n",
    "        #cp = self.batch1(cp)\n",
    "        cp = self.relu1(cp)\n",
    "        cp_copy_1 = cp\n",
    "        \n",
    "        cp = self.conv2(cp)\n",
    "        #cp = self.batch2(cp)\n",
    "        cp = self.relu2(cp)\n",
    "        cp_copy_2 = cp\n",
    "        \n",
    "        cp = self.conv3(cp)\n",
    "        #cp = self.batch3(cp)\n",
    "        cp = self.relu3(cp)\n",
    "        cp_copy_3 = cp\n",
    "        \n",
    "        cp = self.conv4(cp)\n",
    "        #cp = self.batch4(cp)\n",
    "        cp = self.relu4(cp)\n",
    "        cp_copy_4 = cp\n",
    "        \n",
    "        cp = self.conv5(cp)\n",
    "        #cp = self.batch5(cp)\n",
    "        cp = self.relu5(cp)\n",
    "        \n",
    "        global_feature = torch.max(cp, 2)[0]\n",
    "        cp = torch.max(cp, 2)[0].view(-1, self.feature_dimension, 1).repeat(1, 1, N)\n",
    "        tensor_1 = torch.cat([cp_copy_0, cp_copy_1, cp_copy_2, cp_copy_3, cp_copy_4, cp], 1)\n",
    "\n",
    "        if self.isSegmentation:\n",
    "            output = self.conv6(tensor_1)\n",
    "            #output = self.batch6(output)\n",
    "            output = self.relu6(output)\n",
    "            \n",
    "            output = self.conv7(output)\n",
    "            #output = self.batch7(output)\n",
    "            output = self.relu7(output)\n",
    "            \n",
    "            output = self.conv8(output)\n",
    "            #output = self.batch8(output)\n",
    "            output = self.relu8(output)\n",
    "            output = self.dropout1(output)\n",
    "            output = self.conv9(output)\n",
    "            return output\n",
    "        else:\n",
    "            return global_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define PointNet\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension, feature_dimension, isSegmentation):\n",
    "        super(PointNet, self).__init__()\n",
    "        \n",
    "        self.input_dimension = input_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        self.feature_dimension = feature_dimension\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_dimension, 64, 1)\n",
    "        self.batch1 = nn.BatchNorm1d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv1d(64, 64, 1)\n",
    "        self.batch1_1 = nn.BatchNorm1d(64)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv1_2 = nn.Conv1d(64, 64, 1)\n",
    "        self.batch1_2 = nn.BatchNorm1d(64)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.batch2 = nn.BatchNorm1d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, self.feature_dimension, 1)\n",
    "        self.batch3 = nn.BatchNorm1d(self.feature_dimension)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        #self.fc1 = nn.Linear(self.feature_dimension, 256)\n",
    "        #self.batch_1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(256, 128)\n",
    "        #self.batch_2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(128 + self.feature_dimension, 512, 1)\n",
    "        self.batch4 = nn.BatchNorm1d(512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(512, 256, 1)\n",
    "        self.batch5 = nn.BatchNorm1d(256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        #self.dropout5 = nn.Dropout(0.7)\n",
    "        \n",
    "        self.conv6 = nn.Conv1d(256, 128, 1)\n",
    "        self.batch6 = nn.BatchNorm1d(128)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv6_1 = nn.Conv1d(128, 128, 1)\n",
    "        self.batch6_1 = nn.BatchNorm(128)\n",
    "        self.relu6_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv7 = nn.Conv1d(128, self.output_dimension, 1)\n",
    "        \n",
    "        self.isSegmentation = isSegmentation\n",
    "\n",
    "    def forward(self, cp):\n",
    "        B, N = cp.shape[0], cp.shape[1]\n",
    "        cp = cp.permute(0, 2, 1)\n",
    "\n",
    "        cp = self.conv1(cp)\n",
    "        cp = self.batch1(cp)\n",
    "        cp = self.relu1(cp)\n",
    "        \n",
    "        cp = self.conv1_1(cp)\n",
    "        cp = self.batch1_1(cp)\n",
    "        cp = self.relu1_1(cp)\n",
    "        \n",
    "        cp = self.conv1_2(cp)\n",
    "        cp = self.batch1_2(cp)\n",
    "        cp = self.relu1_2(cp)\n",
    "        \n",
    "        cp = self.conv2(cp)\n",
    "        cp = self.batch2(cp)\n",
    "        cp = self.relu2(cp)\n",
    "        \n",
    "        cp_copy = cp\n",
    "        \n",
    "        cp = self.conv3(cp)\n",
    "        cp = self.batch3(cp)\n",
    "        cp = self.relu3(cp)\n",
    "        \n",
    "        cp = torch.max(cp, 2, keepdim=True)[0]\n",
    "        cp = cp.view(-1, self.feature_dimension)\n",
    "        \n",
    "        #cp = F.relu(self.batch_1(self.fc1(cp)), inplace=True)\n",
    "        #cp = F.relu(self.batch_2(self.fc2(cp)), inplace=True)\n",
    "        \n",
    "        if self.isSegmentation:\n",
    "            cp = cp.view(B, 128, 1).repeat(1, 1, N)\n",
    "            tensor_1 = torch.cat([cp_copy, cp], 1)\n",
    "            output = self.conv4(tensor_1)\n",
    "            output = self.batch4(output)\n",
    "            output = self.relu4(output)\n",
    "            \n",
    "            output = self.conv5(output)\n",
    "            output = self.batch5(output)\n",
    "            output = self.relu5(output)\n",
    "            #output = self.dropout5(output)\n",
    "            \n",
    "            output = self.conv6(output)\n",
    "            output = self.batch6(output)\n",
    "            output = self.relu6(output)\n",
    "            \n",
    "            output = self.conv6_1(output)\n",
    "            output = self.batch6_1(output)\n",
    "            output = self.relu6_1(output)\n",
    "            output = self.conv7(output) # [B, num_of_classes, N]\n",
    "            return output\n",
    "        else:\n",
    "            return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define kittiDataset\n",
    "class KittiDataset(Dataset):\n",
    "    def __init__(self, train, num_classes, dataset_path, sample_size, augment):\n",
    "        super(KittiDataset, self).__init__()\n",
    "        self.train = train\n",
    "        self.augment = augment\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        scan = SemLaserScan(num_classes)\n",
    "        frames = []\n",
    "        labels = []\n",
    "\n",
    "        father_files = os.listdir(dataset_path)\n",
    "        for father_file in father_files:\n",
    "            points_path = dataset_path + \"/\" + father_file + \"/velodyne\"\n",
    "            labels_path = dataset_path + \"/\"+ father_file + \"/labels\"\n",
    "            points_files = os.listdir(points_path)\n",
    "            if (int(father_file) <= 10 and int(father_file) != 8 and train == True) or (int(father_file) == 8 and train == False):\n",
    "                for points_file in points_files:\n",
    "                    scan.open_scan(points_path + \"/\" + points_file)\n",
    "                    points = scan.points\n",
    "                    frames.append(points)\n",
    "                    index = points_file.split(\".\")[0]\n",
    "                    scan.open_label(labels_path + \"/\" + index + \".label\")\n",
    "                    labels.append(scan.sem_label)\n",
    "            \n",
    "        self.frames = frames\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        frame = np.array(self.frames[idx])\n",
    "        label = np.array(self.labels[idx], dtype=np.long)\n",
    "        if self.augment and self.train:\n",
    "            sample_indexes = np.array(random.sample(range(0, frame.shape[0]), self.sample_size), dtype=np.long)\n",
    "            if np.random.random() > 0.5:\n",
    "                # Flipping along the YZ plane\n",
    "                frame[:,0] = -1 * frame[:,0]              \n",
    "                \n",
    "            if np.random.random() > 0.5:\n",
    "                # Flipping along the XZ plane\n",
    "                frame[:,1] = -1 * frame[:,1]                              \n",
    "            \n",
    "            # Rotation along up-axis/Z-axis\n",
    "            theta = (np.random.random()*np.pi/18) - np.pi/36 # -5 ~ +5 degree\n",
    "            matrix = np.zeros((3,3))\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            matrix[0, 0] = a\n",
    "            matrix[0, 1] = -b\n",
    "            matrix[1, 0] = b\n",
    "            matrix[1, 1] = a\n",
    "            matrix[2, 2] = 1\n",
    "            frame[:,0:3] = np.dot(frame[:,0:3], np.transpose(matrix))\n",
    "                        \n",
    "            # Rescale randomly by 0.9 - 1.1\n",
    "            proportion = np.random.uniform(0.9, 1.1, 1)\n",
    "            frame = frame * proportion\n",
    "            \n",
    "            return torch.FloatTensor(frame[sample_indexes]), torch.tensor(label[sample_indexes])\n",
    "        else:\n",
    "            random_indexes = np.array(random.sample(range(0, frame.shape[0]), self.sample_size), dtype=np.long)\n",
    "            return torch.FloatTensor(frame[random_indexes]), torch.tensor(label[random_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = KittiDataset(True, NUM_OF_CLASSES, DATASET_PATH, SAMPLE_SIZE, True)\n",
    "val_set = KittiDataset(False, NUM_OF_CLASSES, DATASET_PATH, SAMPLE_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(dataset = training_set, batch_size = BATCH_SIZE, \n",
    "                                 shuffle = True, drop_last = True, num_workers = 2)\n",
    "val_dataloader = DataLoader(dataset = val_set, batch_size = BATCH_SIZE, \n",
    "                            shuffle = False, drop_last = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376\n",
      "1357\n"
     ]
    }
   ],
   "source": [
    "print(len(training_dataloader))\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyiheng/python/lib/python2.7/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/xyiheng/python/lib/python2.7/site-packages/ipykernel_launcher.py:7: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "## Get weight for cross entropy\n",
    "proportion = np.zeros(NUM_OF_CLASSES)\n",
    "with open(\"config/semantic-kitti.yaml\", 'r') as f:\n",
    "    content = yaml.load(f.read())[\"content\"]\n",
    "    \n",
    "with open(\"config/semantic-kitti.yaml\", 'r') as f2:\n",
    "    learning_map = yaml.load(f2.read())[\"learning_map\"]\n",
    "\n",
    "for key in learning_map:\n",
    "    proportion[learning_map[key]] += content[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize weight\n",
    "sum = np.sum(proportion[1:])\n",
    "new_proportion = proportion / sum\n",
    "weight = np.sqrt(np.sqrt(1 / proportion))\n",
    "weight[0] = 0\n",
    "weight = torch.FloatTensor(weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net = PointNet_new(3, 20, 2048, True)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0, weight=weight)\n",
    "optimizer = torch.optim.Adam(point_net.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in point_net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = \"{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now())\n",
    "writer = SummaryWriter(\"runs/loss\" + TIMESTAMP)\n",
    "\n",
    "point_net.to(device)\n",
    "for epoch in range(5000):\n",
    "    if (epoch+1) % 4 == 0: # every 3 epochs update\n",
    "        lr_scheduler.step()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "    break_signal= False\n",
    "    for i, data in enumerate(training_dataloader, 0):\n",
    "        #if epoch == 1 and i == 3000:\n",
    "            #break_signal = True\n",
    "        point_net.train()\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = point_net(X)\n",
    "               \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        if i % 200 == 199:\n",
    "            with torch.no_grad():\n",
    "                point_net.eval()\n",
    "                for j, data2 in enumerate(val_dataloader, 0):\n",
    "                    X_val, y_val = data2\n",
    "                    X_val = X_val.to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    y_pred = point_net(X_val)\n",
    "                    val_running_loss += criterion(y_pred, y_val).item()\n",
    "                    \n",
    "                    _, preds = torch.max(y_pred, 1)\n",
    "                    correct += preds.eq(y_val).sum().item()\n",
    "                    total += y_val.size(0) * y_val.size(1)\n",
    "        \n",
    "            train_running_loss /= 200\n",
    "            val_running_loss /= j\n",
    "            correct /= total\n",
    "        \n",
    "            with open('loss.txt','a') as f:\n",
    "                f.write(\"[Epoch %d, Iteration %5d] train_loss: %.3f acc: %.2f %% val_loss: %.3f\\n\" % \n",
    "                    (epoch+1, i+1, train_running_loss, 100*correct, val_running_loss))\n",
    "        \n",
    "            writer.add_scalars('loss', {'training_loss':train_running_loss,\n",
    "                                        'val_loss':val_running_loss}, epoch * len(training_dataloader) + i)\n",
    "        \n",
    "            train_running_loss = 0.0\n",
    "            val_running_loss = 0.0\n",
    "            correct = 0.0\n",
    "            total = 0\n",
    "    if break_signal:\n",
    "        break\n",
    "\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(point_net_2.state_dict(), \"point_net_2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net = PointNet2(20)\n",
    "point_net.load_state_dict(torch.load(\"point_net_2_1\"))\n",
    "point_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build test/val results & confusion matrix\n",
    "#c_matrix = np.zeros((20, 20))\n",
    "scan = SemLaserScan(NUM_OF_CLASSES)\n",
    "father_files = os.listdir(DATASET_PATH)\n",
    "for father_file in father_files:\n",
    "    points_path = DATASET_PATH + \"/\" + father_file + \"/velodyne\"\n",
    "    points_files = os.listdir(points_path)\n",
    "    labels_path = DATASET_PATH + \"/\"+ father_file + \"/labels\"\n",
    "    if int(father_file) == 8:\n",
    "        for points_file in points_files:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            scan.open_scan(points_path + \"/\" + points_file)\n",
    "            X_test = scan.points\n",
    "            X_test = torch.FloatTensor(X_test)\n",
    "            \n",
    "            index = points_file.split(\".\")[0]\n",
    "            scan.open_label(labels_path + \"/\" + index + \".label\")\n",
    "            y = scan.sem_label\n",
    "            \n",
    "            # to save memory of cuda, split it into 2 parts\n",
    "            X1 = X_test[0: 50000, :]\n",
    "            X2 = X_test[50000:, :]\n",
    "            X1 = X1.to(device)\n",
    "            X1 = X1.view(1, -1, 3)\n",
    "            X1 = X1.permute(0, 2, 1)\n",
    "            y1 = point_net_2(X1)\n",
    "            _, preds1 = torch.max(y1, 1)\n",
    "            \n",
    "            X2 = X2.to(device)\n",
    "            X2 = X2.view(1, -1, 3)\n",
    "            X2 = X2.permute(0, 2, 1)\n",
    "            y2 = point_net_2(X2)\n",
    "            _, preds2 = torch.max(y2, 1)\n",
    "           \n",
    "            preds = torch.cat([preds1, preds2], dim=1)\n",
    "            preds = preds.cpu()\n",
    "            y = np.array(y, dtype=np.uint8)\n",
    "            y = torch.LongTensor(y).view(1, -1)\n",
    "            correct = preds.eq(y).sum().item()\n",
    "            total = y.size(0) * y.size(1)\n",
    "            \n",
    "            preds = preds.cpu()\n",
    "            # build confusion matrix -> rows are ground truth labels, columns are predicted labels\n",
    "            for i in range(y.shape[0]):\n",
    "                if y[i] == preds[i]:\n",
    "                    c_matrix[y[i], y[i]] += 1\n",
    "                else:\n",
    "                    c_matrix[y[i], preds[i]] += 1\n",
    "            np.array(preds, dtype=np.uint32).tofile(TESTLABEL_PATH + \"/\" + father_file + \"/\" + \"predictions/\" + index + \".label\", sep=\"\", format=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate accuracy\n",
    "accuracy = []\n",
    "for i in range(c_matrix.shape[0]):\n",
    "    accuracy.append(c_matrix[i, i] / np.sum(c_matrix[i]))\n",
    "accuracy = np.array(accuracy)\n",
    "average_accuracy = np.sum(accuracy[1:]) / 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## START POINT_NET++ #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, C]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz, num_centroids):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        num_centroids: number of samples(centroids)\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, num_centroids, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(num_centroids):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        radius: local region radius\n",
    "        nsample: max sample number in local region\n",
    "        xyz: all points, [B, N, 3]\n",
    "        new_xyz: query points, [B, S, 3]\n",
    "    Return:\n",
    "        group_idx: grouped points index, [B, S, nsample]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_group(xyz, feature, num_centroids, num_neighbors, radius):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: input points position data, [B, N, 3]\n",
    "        feature: input feature data, [B, N, D]\n",
    "        num_centroids:\n",
    "        num_neighbors:\n",
    "        radius:\n",
    "    Return:\n",
    "        centroids: sampled points position data, [B, num_centroids, num_neighbors, 3]\n",
    "        new_points: sampled position+feature data, [B, num_centroids, num_neighbors, 3 + D]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    S = num_centroids\n",
    "    # get centroids\n",
    "    centroids_index = farthest_point_sample(xyz, num_centroids) # [B, num_centroids]\n",
    "    centroids = index_points(xyz, centroids_index)\n",
    "    neighbors_index = query_ball_point(radius, num_neighbors, xyz, centroids)\n",
    "    neighbors = index_points(xyz, neighbors_index) # [B, npoint, nsample, C]\n",
    "    neighbors_norm = neighbors - centroids.view(B, S, 1, C)\n",
    "    \n",
    "    if feature is not None:\n",
    "        feature_neighbors = index_points(feature, neighbors_index)\n",
    "        new_points = torch.cat([neighbors_norm, feature_neighbors], dim = -1)\n",
    "    else:\n",
    "        new_points = neighbors_norm\n",
    "    \n",
    "    return centroids, new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, num_centroids, radius, num_neighbors, in_channel, mlp):\n",
    "        super(PointNetSetAbstraction, self).__init__()\n",
    "        self.num_centroids = num_centroids\n",
    "        self.radius = radius\n",
    "        self.num_neighbors = num_neighbors\n",
    "        \n",
    "        self.conv_list = nn.ModuleList()\n",
    "        #self.bn_list = nn.ModuleList()\n",
    "        \n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.conv_list.append(nn.Conv2d(last_channel, out_channel, 1, 1))\n",
    "            #self.bn_list.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "        \n",
    "    def forward(self, xyz, feature):\n",
    "        # xyz: [B, C, N] feature: [B, D, N]\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if feature is not None:\n",
    "            feature = feature.permute(0, 2, 1)\n",
    "        \n",
    "        centroids, new_points = sample_and_group(xyz, feature, self.num_centroids, self.num_neighbors, self.radius)\n",
    "        # new_points [B, num_centroids, num_neighbors, 3 + D]\n",
    "        new_points = new_points.permute(0, 3, 2, 1) # [B, 3 + D, num_neighbors, num_centroids]\n",
    "        for i, conv in enumerate(self.conv_list):\n",
    "            #bn = self.bn_list[i]\n",
    "            new_points =  F.relu((conv(new_points)), inplace=True)\n",
    "        new_points = torch.max(new_points, 2)[0] # dim = 2 -> reduce the third dimension = num_neighbors\n",
    "        new_xyz = centroids.permute(0, 2, 1) # from [B, N, C] to [B, C, N]\n",
    "        return new_xyz, new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super(PointNetFeaturePropagation, self).__init__()\n",
    "        self.conv_list = nn.ModuleList()\n",
    "        #self.bn_list = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.conv_list.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            #self.bn_list.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "    \n",
    "    def forward(self, xyz1, xyz2, feature1, feature2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz1: input points position data, [B, C, N]\n",
    "            xyz2: sampled input points position data, [B, C, S]\n",
    "            feature1: input feature data, [B, D, N]\n",
    "            feature2: input feature data, [B, D, S]\n",
    "        Return:\n",
    "            new_feature: upsampled feature data, [B, D', N]\n",
    "        \"\"\"\n",
    "        xyz1 = xyz1.permute(0, 2, 1) # [B, N, C]\n",
    "        xyz2 = xyz2.permute(0, 2, 1) # [B, S, C]\n",
    "        \n",
    "        B = xyz1.shape[0]\n",
    "        N = xyz1.shape[1]\n",
    "        S = xyz2.shape[1]\n",
    "        D = feature2.shape[1]\n",
    "        \n",
    "        dists = square_distance(xyz1, xyz2)\n",
    "        dists, idx = dists.sort(dim = -1) # [B, N, S]\n",
    "        dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
    "        \n",
    "        dist_rev = 1.0 / (dists + 1e-8) # [B, N, 3]\n",
    "        norm = torch.sum(dist_rev, dim = 2, keepdim = True) # [B, N, 3]\n",
    "        weights = dist_rev / norm # [B, N, 3]\n",
    "        \n",
    "        feature2 = feature2.permute(0, 2, 1) # [B, S, D]\n",
    "        interpolated_feature = torch.sum(index_points(feature2, idx) * weights.view(B, N, 3, 1), dim=2)\n",
    "        \n",
    "        if feature1 is None:\n",
    "            new_feature = interpolated_feature\n",
    "        else:\n",
    "            feature1 = feature1.permute(0, 2, 1) # [B, N, D]\n",
    "            new_feature = torch.cat([feature1, interpolated_feature], dim = -1) # [B, N, D + ?]\n",
    "        \n",
    "        new_feature = new_feature.permute(0, 2, 1) #[B, D + ?, N]\n",
    "        \n",
    "        for i, conv in enumerate(self.conv_list):\n",
    "            #bn = self.bn_list[i]\n",
    "            new_feature = F.relu((conv(new_feature)), inplace=True)\n",
    "        return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNet2, self).__init__()\n",
    "        self.sa1 = PointNetSetAbstraction(1024, 2, 64, 3, [32, 32, 64])\n",
    "        self.sa2 = PointNetSetAbstraction(512, 4, 64, 64 + 3, [64, 64, 128])\n",
    "        self.sa3 = PointNetSetAbstraction(256, 6, 64, 128 + 3, [128, 128, 256])\n",
    "        self.sa4 = PointNetSetAbstraction(128, 8, 64, 256 + 3, [256, 256, 512])\n",
    "        self.fp4 = PointNetFeaturePropagation(768, [256, 256])\n",
    "        self.fp3 = PointNetFeaturePropagation(384, [256, 256])\n",
    "        self.fp2 = PointNetFeaturePropagation(320, [256, 128])\n",
    "        self.fp1 = PointNetFeaturePropagation(128, [128, 128, 128])\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        #self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, xyz):\n",
    "        # xyz: [B, 3, N]\n",
    "        xyz_0 = xyz[:,0:3,:]\n",
    "        feature_0 = None\n",
    "        B, N = xyz.shape[0], xyz.shape[2]\n",
    "        \n",
    "        xyz_1, feature_1 = self.sa1(xyz_0, feature_0)\n",
    "        xyz_2, feature_2 = self.sa2(xyz_1, feature_1)\n",
    "        xyz_3, feature_3 = self.sa3(xyz_2, feature_2)\n",
    "        xyz_4, feature_4 = self.sa4(xyz_3, feature_3)\n",
    "        \n",
    "        feature_3 = self.fp4(xyz_3, xyz_4, feature_3, feature_4)\n",
    "        feature_2 = self.fp3(xyz_2, xyz_3, feature_2, feature_3)\n",
    "        feature_1 = self.fp2(xyz_1, xyz_2, feature_1, feature_2)\n",
    "        feature_0 = self.fp1(xyz_0, xyz_1, feature_0, feature_1)\n",
    "        \n",
    "        output = self.conv1(feature_0)\n",
    "        #output = self.bn1(output)\n",
    "        output = self.drop1(F.relu(output))\n",
    "        output = self.conv2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net_2 = PointNet2(20)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=0)\n",
    "optimizer = torch.optim.Adam(point_net_2.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in point_net_2.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Conv1d)):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in point_net_2.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = \"{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now())\n",
    "writer = SummaryWriter(\"runs/loss\" + TIMESTAMP)\n",
    "\n",
    "point_net_2.to(device)\n",
    "for epoch in range(10):\n",
    "    if (epoch+1) % 4 == 0:# every 3 epoch update\n",
    "        lr_scheduler.step()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "    break_signal= False\n",
    "    for i, data in enumerate(training_dataloader, 0):\n",
    "        point_net_2.train()\n",
    "        X, y = data\n",
    "        X = X.permute(0, 2, 1)\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = point_net_2(X)\n",
    "               \n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        if i % 300 == 299:\n",
    "            with torch.no_grad():\n",
    "                point_net_2.eval()\n",
    "                for j, data2 in enumerate(val_dataloader, 0):\n",
    "                    if (((i+1)/300) % 2 == 0 and (j+1) % 2 == 0) or (((i+1)/300) % 2 > 0 and (j+1) % 2 > 0):\n",
    "                        X_val, y_val = data2\n",
    "                        X_val = X_val.permute(0, 2, 1)\n",
    "                        X_val = X_val.to(device)\n",
    "                        y_val = y_val.to(device)\n",
    "                        y_pred = point_net_2(X_val)\n",
    "                        val_running_loss += criterion(y_pred, y_val).item()\n",
    "                    \n",
    "                        _, preds = torch.max(y_pred, 1)\n",
    "                        correct += preds.eq(y_val).sum().item()\n",
    "                        total += y_val.size(0) * y_val.size(1)\n",
    "        \n",
    "            train_running_loss /= 300\n",
    "            val_running_loss /= (j/2)\n",
    "            correct /= total\n",
    "        \n",
    "            with open('loss.txt','a') as f:\n",
    "                f.write(\"[Epoch %d, Iteration %5d] train_loss: %.3f acc: %.2f %% val_loss: %.3f\\n\" % \n",
    "                    (epoch+1, i+1, train_running_loss, 100*correct, val_running_loss))\n",
    "        \n",
    "            writer.add_scalars('loss', {'training_loss':train_running_loss,\n",
    "                                        'val_loss':val_running_loss}, epoch * len(training_dataloader) + i)\n",
    "        \n",
    "            train_running_loss = 0.0\n",
    "            val_running_loss = 0.0\n",
    "            correct = 0.0\n",
    "            total = 0\n",
    "    if break_signal:\n",
    "        break\n",
    "\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net_2.eval()\n",
    "#torch.save(point_net_2.state_dict(), \"point_net_2_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net_2 = PointNet2(20)\n",
    "point_net_2.to(device)\n",
    "point_net_2.load_state_dict(torch.load(\"point_net_2_1\"))\n",
    "point_net_2.eval()\n",
    "c_matrix = np.zeros((20, 20))\n",
    "for j, data2 in enumerate(val_dataloader, 0):\n",
    "    total = 0\n",
    "    correct = 0.0\n",
    "    X_val, y_val = data2\n",
    "    X_val = X_val.permute(0, 2, 1)\n",
    "    X_val = X_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    y_pred = point_net_2(X_val)\n",
    "                    \n",
    "    _, preds = torch.max(y_pred, 1)\n",
    "    \n",
    "    # build confusion matrix -> rows are ground truth labels, columns are predicted labels\n",
    "    for i in range(y_val.shape[0]):\n",
    "        for k in range(y_val.shape[1]):\n",
    "            if y_val[i, k] == preds[i, k]:\n",
    "                c_matrix[y_val[i, k], y_val[i, k]] += 1\n",
    "            else:\n",
    "                c_matrix[y_val[i, k], preds[i, k]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_new = c_matrix[1:, 1:]\n",
    "print(c_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[0,0]\n",
    "sum = np.sum(c_new[0]) + np.sum(c_new[1:, 0])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[1,1]\n",
    "sum = np.sum(c_new[1]) + np.sum(c_new[2:, 1]) + c_new[0,1]\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[2,2]\n",
    "sum = np.sum(c_new[2]) + np.sum(c_new[3:, 2]) + np.sum(c_new[0:1,2])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[3,3]\n",
    "sum = np.sum(c_new[3]) + np.sum(c_new[4:, 3]) + np.sum(c_new[0:2,3])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[4,4]\n",
    "sum = np.sum(c_new[4]) + np.sum(c_new[5:, 4]) + np.sum(c_new[0:3,4])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[5,5]\n",
    "sum = np.sum(c_new[5]) + np.sum(c_new[6:, 5]) + np.sum(c_new[0:4,5])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[6,6]\n",
    "sum = np.sum(c_new[6]) + np.sum(c_new[7:, 6]) + np.sum(c_new[0:5,6])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[7,7]\n",
    "sum = np.sum(c_new[7]) + np.sum(c_new[8:, 7]) + np.sum(c_new[0:6,7])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[8,8]\n",
    "sum = np.sum(c_new[8]) + np.sum(c_new[9:, 8]) + np.sum(c_new[0:7,8])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[9,9]\n",
    "sum = np.sum(c_new[9]) + np.sum(c_new[10:, 9]) + np.sum(c_new[0:8,9])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[10,10]\n",
    "sum = np.sum(c_new[10]) + np.sum(c_new[11:, 10]) + np.sum(c_new[0:9,10])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[11,11]\n",
    "sum = np.sum(c_new[11]) + np.sum(c_new[12:, 11]) + np.sum(c_new[0:10,11])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[12,12]\n",
    "sum = np.sum(c_new[12]) + np.sum(c_new[13:, 12]) + np.sum(c_new[0:11,12])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[13,13]\n",
    "sum = np.sum(c_new[13]) + np.sum(c_new[14:, 13]) + np.sum(c_new[0:12,13])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[14,14]\n",
    "sum = np.sum(c_new[14]) + np.sum(c_new[15:, 14]) + np.sum(c_new[0:13,14])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[15,15]\n",
    "sum = np.sum(c_new[15]) + np.sum(c_new[16:, 15]) + np.sum(c_new[0:14,15])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[16,16]\n",
    "sum = np.sum(c_new[16]) + np.sum(c_new[17:, 16]) + np.sum(c_new[0:15,16])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[17,17]\n",
    "sum = np.sum(c_new[17]) + np.sum(c_new[18:, 17]) + np.sum(c_new[0:16,17])\n",
    "print(a / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c_new[18,18]\n",
    "sum = np.sum(c_new[18]) + np.sum(c_new[0:17,18])\n",
    "print(a / sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
